[package]
name = "burn-models-cli"
version = "0.1.0"
edition.workspace = true
rust-version.workspace = true
description = "Command-line interface for burn-models (Stable Diffusion, LLMs)"
license.workspace = true

[[bin]]
name = "burn-models"
path = "src/main.rs"

[[bin]]
name = "inspect-safetensors"
path = "src/bin/inspect-safetensors.rs"

[features]
default = ["wgpu", "cpu"]
# For NVIDIA GPUs, build with: cargo build --features cuda
cpu = ["burn-cpu"]
ndarray = ["burn-models/ndarray", "burn-ndarray"]
tch = ["burn-models/tch"]
wgpu = ["burn-models/wgpu", "burn-wgpu"]
cuda = ["burn-models/cuda", "burn-cuda"]
llm-serve = ["burn-models-llm/serve", "tokio"]

[dependencies]
burn = { workspace = true }
burn-models = { path = "../burn-models" }
burn-models-llm = { path = "../burn-models-llm" }
burn-models-convert = { path = "../burn-models-convert" }
burn-models-clip = { path = "../burn-models-clip" }
burn-models-unet = { path = "../burn-models-unet" }
burn-models-vae = { path = "../burn-models-vae" }
burn-models-samplers = { path = "../burn-models-samplers" }
clap = { version = "4.5", features = ["derive"] }
image = "0.25"
anyhow = "1.0"
indicatif = "0.17"
memmap2 = "0.9"
safetensors = "0.5"
half = "2"

# Backend dependencies (optional)
burn-ndarray = { workspace = true, optional = true }
burn-wgpu = { workspace = true, optional = true }
burn-cuda = { workspace = true, optional = true }
burn-cpu = { version = "0.20.0-pre.6", optional = true, default-features = false }

# Serve dependencies (optional)
tokio = { version = "1", features = ["full"], optional = true }
